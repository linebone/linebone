{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import data\n",
    "from os import path\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from codes.model import KGEModel\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To run this notebook, please train a kge model first.\n",
    "### See the script 'linebone/kge/best_config.sh' to run a kge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dataset = \"wn18rr\"\n",
    "# name_dataset = \"FB15k-237\"\n",
    "# name_dataset = \"YAGO3-10\"\n",
    "\n",
    "# name_model = \"TransE\"\n",
    "name_model = \"pRotatE\"\n",
    "# name_model = \"RotatE\"\n",
    "\n",
    "data_path = f\"data/{name_dataset}\"\n",
    "model_dir = f\"models/{name_model}_{name_dataset}_0\"\n",
    "checkpoint_dir = f\"models/{name_model}_{name_dataset}_0/checkpoint\"\n",
    "config_dir = f\"models/{name_model}_{name_dataset}_0/config.json\"\n",
    "\n",
    "# load config\n",
    "with open(config_dir, 'r') as fjson:\n",
    "    argparse_dict = json.load(fjson)\n",
    "model = argparse_dict['model']\n",
    "double_entity_embedding = argparse_dict['double_entity_embedding']\n",
    "double_relation_embedding = argparse_dict['double_relation_embedding']\n",
    "hidden_dim = argparse_dict['hidden_dim']\n",
    "gamma = argparse_dict['gamma']\n",
    "# test_batch_size = argparse_dict['test_batch_size']\n",
    "\n",
    "ent2id = {}\n",
    "rel2id = {}\n",
    "with open(os.path.join(data_path, 'entities.dict')) as fin:\n",
    "    for line in fin:\n",
    "        eid, entity = line.strip().split('\\t')\n",
    "        ent2id[entity] = int(eid)\n",
    "with open(os.path.join(data_path, 'relations.dict')) as fin:\n",
    "    for line in fin:\n",
    "        rid, relation = line.strip().split('\\t')\n",
    "        rel2id[relation] = int(rid)\n",
    "\n",
    "def read_triples(file_path):\n",
    "    triples = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            h, r, t = line.strip().split('\\t')\n",
    "            triples.append((ent2id[h], rel2id[r], ent2id[t]))\n",
    "    return triples\n",
    "\n",
    "id2ent = {v:k for k,v in ent2id.items()}\n",
    "id2rel = {v:k for k,v in rel2id.items()}\n",
    "\n",
    "num_ent = len(ent2id)\n",
    "num_rel = len(rel2id)\n",
    "\n",
    "train_triples = read_triples(os.path.join(data_path, 'train.txt'))\n",
    "valid_triples = read_triples(os.path.join(data_path, 'valid.txt'))\n",
    "test_triples = read_triples(os.path.join(data_path, 'test.txt'))\n",
    "\n",
    "#All true triples\n",
    "all_true_triples = train_triples + valid_triples + test_triples\n",
    "\n",
    "kge_model = KGEModel(\n",
    "    model_name=name_model,\n",
    "    nentity=num_ent,\n",
    "    nrelation=num_rel,\n",
    "    hidden_dim=hidden_dim,\n",
    "    gamma=gamma,\n",
    "    double_entity_embedding=double_entity_embedding,\n",
    "    double_relation_embedding=double_relation_embedding\n",
    ")\n",
    "\n",
    "# load model\n",
    "checkpoint = torch.load(checkpoint_dir)\n",
    "kge_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "kge_model = kge_model.cuda()\n",
    "\n",
    "# load embedding\n",
    "entity_embedding = kge_model.entity_embedding\n",
    "relation_embedding = kge_model.relation_embedding\n",
    "\n",
    "# load other config\n",
    "epsilon = kge_model.epsilon\n",
    "embedding_range = kge_model.embedding_range\n",
    "entity_dim = kge_model.entity_dim\n",
    "relation_dim = kge_model.relation_dim\n",
    "gamma = kge_model.gamma\n",
    "\n",
    "if name_model == 'pRotatE':\n",
    "    modulus = kge_model.modulus\n",
    "\n",
    "# split dataset and output rel_type subdataset\n",
    "def filtered_dataset(triples, rel_type):\n",
    "    rst = set()\n",
    "    for head, rel, tail in triples:\n",
    "        if rel in rel_type:\n",
    "            rst.add((head, rel, tail))\n",
    "    return rst\n",
    "\n",
    "# calculate proportion of each rel_type\n",
    "proportion = torch.zeros(num_rel)\n",
    "for triple in test_triples:\n",
    "    proportion[triple[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for wn18rr and yago3-10\n",
    "# if you want to change dataset to fb15k-237, please comment this notebook block and use the next block.\n",
    "def get_subset_rel(batch_type, A_set, B_set):\n",
    "    rst = []\n",
    "    threshold = 2\n",
    "    _1N = {}\n",
    "    for rel in A_set.keys():\n",
    "        tmp = 0\n",
    "        for head in A_set[rel].keys():\n",
    "            if len(A_set[rel][head]) >= threshold:\n",
    "                tmp += 1\n",
    "        _1N[rel] = tmp / len(A_set[rel])\n",
    "    id2relation = {v:k for k,v in rel2id.items()}\n",
    "    _N1 = {}\n",
    "    for rel in B_set.keys():\n",
    "        tmp = 0\n",
    "        for tail in B_set[rel].keys():\n",
    "            if len(B_set[rel][tail]) >= threshold:\n",
    "                tmp += 1\n",
    "        _N1[rel] = tmp / len(B_set[rel])\n",
    "    if batch_type == BatchType.HEAD_BATCH:\n",
    "        for rel in A_set.keys():\n",
    "            if _N1[rel] - _1N[rel] > 0.25 and _N1[rel] > 0.5:\n",
    "                rst.append(rel)\n",
    "        print(\"N-1 rel:\", [id2relation[i] for i in rst])\n",
    "    elif batch_type == BatchType.TAIL_BATCH:\n",
    "        for rel in B_set.keys():\n",
    "            if _1N[rel] - _N1[rel] > 0.2 and _1N[rel] > 0.2:\n",
    "                rst.append(rel)\n",
    "        print(\"1-N rel:\", [id2relation[i] for i in rst])\n",
    "    return rst\n",
    "\n",
    "def get_11_rel(A_set, B_set):\n",
    "    rst = []\n",
    "    threshold = 2\n",
    "    proportion_threshold = 0.25\n",
    "    _1N = {}\n",
    "    for rel in A_set.keys():\n",
    "        tmp = 0\n",
    "        for head in A_set[rel].keys():\n",
    "            if len(A_set[rel][head]) >= threshold:\n",
    "                tmp += 1\n",
    "        _1N[rel] = tmp / len(A_set[rel])\n",
    "    id2relation = {v:k for k,v in rel2id.items()}\n",
    "    _N1 = {}\n",
    "    for rel in B_set.keys():\n",
    "        tmp = 0\n",
    "        for tail in B_set[rel].keys():\n",
    "            if len(B_set[rel][tail]) >= threshold:\n",
    "                tmp += 1\n",
    "        _N1[rel] = tmp / len(B_set[rel])\n",
    "    for rel in A_set.keys():\n",
    "        if _N1[rel] <= proportion_threshold and _1N[rel] <= proportion_threshold:\n",
    "            rst.append(rel)\n",
    "    print(\"1-1 rel:\", [id2relation[i] for i in rst])\n",
    "    return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this is the block for fb15k-237\n",
    "# def get_subset_rel(batch_type, A_set, B_set):\n",
    "#     rst = []\n",
    "#     threshold = 2\n",
    "#     _1N = {}\n",
    "#     for rel in A_set.keys():\n",
    "#         tmp = 0\n",
    "#         for head in A_set[rel].keys():\n",
    "#             if len(A_set[rel][head]) >= threshold:\n",
    "#                 tmp += 1\n",
    "#         _1N[rel] = tmp / len(A_set[rel])\n",
    "#     id2relation = {v:k for k,v in rel2id.items()}\n",
    "#     _N1 = {}\n",
    "#     for rel in B_set.keys():\n",
    "#         tmp = 0\n",
    "#         for tail in B_set[rel].keys():\n",
    "#             if len(B_set[rel][tail]) >= threshold:\n",
    "#                 tmp += 1\n",
    "#         _N1[rel] = tmp / len(B_set[rel])\n",
    "#     if batch_type == BatchType.HEAD_BATCH:\n",
    "#         for rel in A_set.keys():\n",
    "#             if _N1[rel] - _1N[rel] > 0.4 and _N1[rel] > 0.7:\n",
    "#                 rst.append(rel)\n",
    "#         # print(\"N-1 rel:\", [id2relation[i] for i in rst])\n",
    "#     elif batch_type == BatchType.TAIL_BATCH:\n",
    "#         for rel in B_set.keys():\n",
    "#             if _1N[rel] - _N1[rel] > 0.525 and _1N[rel] > 0.6:\n",
    "#                 rst.append(rel)\n",
    "#         # print(\"1-N rel:\", [id2relation[i] for i in rst])\n",
    "#     return rst\n",
    "\n",
    "# def get_11_rel(A_set, B_set):\n",
    "#     rst = []\n",
    "#     threshold = 2\n",
    "#     proportion_threshold = 0.2\n",
    "#     _1N = {}\n",
    "#     for rel in A_set.keys():\n",
    "#         tmp = 0\n",
    "#         for head in A_set[rel].keys():\n",
    "#             if len(A_set[rel][head]) >= threshold:\n",
    "#                 tmp += 1\n",
    "#         _1N[rel] = tmp / len(A_set[rel])\n",
    "#     id2relation = {v:k for k,v in rel2id.items()}\n",
    "#     _N1 = {}\n",
    "#     for rel in B_set.keys():\n",
    "#         tmp = 0\n",
    "#         for tail in B_set[rel].keys():\n",
    "#             if len(B_set[rel][tail]) >= threshold:\n",
    "#                 tmp += 1\n",
    "#         _N1[rel] = tmp / len(B_set[rel])\n",
    "#     for rel in A_set.keys():\n",
    "#         if _N1[rel] <= proportion_threshold and _1N[rel] <= proportion_threshold:\n",
    "#             rst.append(rel)\n",
    "#     # print(\"1-1 rel:\", [id2relation[i] for i in rst])\n",
    "#     return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-1 rel: ['_hypernym', '_instance_hypernym', '_synset_domain_topic_of']\n",
      "1-N rel: ['_member_meronym', '_has_part', '_member_of_domain_usage', '_member_of_domain_region']\n",
      "1-1 rel: ['_verb_group', '_similar_to']\n",
      "\n",
      "complex_rel_dist:  tensor([0.0134, 0.4745, 0.1516, 0.3606])\n"
     ]
    }
   ],
   "source": [
    "# get complex rel type\n",
    "class BatchType(Enum):\n",
    "    HEAD_BATCH = 0\n",
    "    TAIL_BATCH = 1\n",
    "    SINGLE = 2\n",
    "\n",
    "def generate_get_tail_find_head():\n",
    "    got_tail_find_head = {}\n",
    "    got_head_find_tail = {}\n",
    "\n",
    "    for head, rel, tail in train_triples:\n",
    "        if rel not in got_tail_find_head.keys():\n",
    "            got_tail_find_head[rel] = {}\n",
    "        if rel not in got_head_find_tail.keys():\n",
    "            got_head_find_tail[rel] = {}\n",
    "        else:\n",
    "            if tail not in got_tail_find_head[rel].keys():\n",
    "                got_tail_find_head[rel][tail] = set()\n",
    "            if head not in got_head_find_tail[rel].keys():\n",
    "                got_head_find_tail[rel][head] = set()\n",
    "            got_tail_find_head[rel][tail].add(head)\n",
    "            got_head_find_tail[rel][head].add(tail)\n",
    "\n",
    "    _N1_rel = get_subset_rel(BatchType.HEAD_BATCH, got_head_find_tail, got_tail_find_head)\n",
    "    _1N_rel = get_subset_rel(BatchType.TAIL_BATCH, got_head_find_tail, got_tail_find_head)\n",
    "    _sym_rel = get_11_rel(got_head_find_tail, got_tail_find_head)\n",
    "\n",
    "    return _N1_rel, _1N_rel, _sym_rel\n",
    "\n",
    "num_complex_rel_type = 4\n",
    "_N1_rel, _1N_rel, _sym_rel = generate_get_tail_find_head()\n",
    "\n",
    "print()\n",
    "\n",
    "complex_rel_idx_dict = defaultdict(list)\n",
    "for rel in range(num_rel):\n",
    "    if rel in _sym_rel:\n",
    "        complex_rel_idx_dict['one2one'].append(rel)\n",
    "    elif rel in _N1_rel:\n",
    "        complex_rel_idx_dict['many2one'].append(rel)\n",
    "    elif rel in _1N_rel:\n",
    "        complex_rel_idx_dict['one2many'].append(rel)\n",
    "    else:\n",
    "        complex_rel_idx_dict['many2many'].append(rel)\n",
    "\n",
    "# implicit need: _N1_rel, _1N_rel, _sym_rel\n",
    "def complex_rel_triples_gen(triples):\n",
    "    one2one, many2one, one2many, many2many = set(), set(), set(), set()\n",
    "    for head, rel, tail in triples:\n",
    "        if rel in _sym_rel:\n",
    "            one2one.add((head, rel, tail))\n",
    "        elif rel in _N1_rel:\n",
    "            many2one.add((head, rel, tail))\n",
    "        elif rel in _1N_rel:\n",
    "            one2many.add((head, rel, tail))\n",
    "        else:\n",
    "            many2many.add((head, rel, tail))\n",
    "    return [one2one, many2one, one2many, many2many]\n",
    "\n",
    "\n",
    "# complex_rel_dist\n",
    "complex_rel_dist = torch.zeros(4)\n",
    "complex_rel_dist[0] = proportion[complex_rel_idx_dict['one2one']].sum()\n",
    "complex_rel_dist[1] = proportion[complex_rel_idx_dict['many2one']].sum()\n",
    "complex_rel_dist[2] = proportion[complex_rel_idx_dict['one2many']].sum()\n",
    "complex_rel_dist[3] = proportion[complex_rel_idx_dict['many2many']].sum()\n",
    "complex_rel_dist /= complex_rel_dist.sum()\n",
    "print(\"complex_rel_dist: \", complex_rel_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known 2 finding 1\n",
    "def get_table(dataset):\n",
    "    table_head = defaultdict(list)\n",
    "    table_tail = defaultdict(list)\n",
    "    for head, rel, tail in dataset:\n",
    "        table_head[(rel, tail)].append(head)\n",
    "        table_tail[(rel, head)].append(tail)\n",
    "    return table_head, table_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 11])\n",
      "dataset size:  1251\n",
      "rel 0 done\n",
      "dataset size:  1074\n",
      "rel 1 done\n",
      "dataset size:  122\n",
      "rel 2 done\n",
      "dataset size:  56\n",
      "rel 3 done\n",
      "dataset size:  253\n",
      "rel 4 done\n",
      "dataset size:  114\n",
      "rel 5 done\n",
      "dataset size:  172\n",
      "rel 6 done\n",
      "dataset size:  24\n",
      "rel 7 done\n",
      "dataset size:  26\n",
      "rel 8 done\n",
      "dataset size:  39\n",
      "rel 9 done\n",
      "dataset size:  3\n",
      "rel 10 done\n",
      "torch.Size([500, 11])\n",
      "dataset size:  1251\n",
      "rel 0 done\n",
      "dataset size:  1074\n",
      "rel 1 done\n",
      "dataset size:  122\n",
      "rel 2 done\n",
      "dataset size:  56\n",
      "rel 3 done\n",
      "dataset size:  253\n",
      "rel 4 done\n",
      "dataset size:  114\n",
      "rel 5 done\n",
      "dataset size:  172\n",
      "rel 6 done\n",
      "dataset size:  24\n",
      "rel 7 done\n",
      "dataset size:  26\n",
      "rel 8 done\n",
      "dataset size:  39\n",
      "rel 9 done\n",
      "dataset size:  3\n",
      "rel 10 done\n"
     ]
    }
   ],
   "source": [
    "# N1 means head testing\n",
    "# 1N means tail testing\n",
    "def TransE(head, relation, tail, mode):\n",
    "    if mode == 'N1':\n",
    "        score = head + (relation - tail)\n",
    "    else:\n",
    "        score = (head + relation) - tail\n",
    "\n",
    "    # score = gamma.item() - torch.norm(score, p=1, dim=2)\n",
    "    score = gamma.item() - torch.abs(score)\n",
    "    return score.squeeze()\n",
    "\n",
    "def RotatE(head, relation, tail, mode):\n",
    "    pi = 3.14159265358979323846\n",
    "    \n",
    "    re_head, im_head = torch.chunk(head, 2, dim=-1)\n",
    "    re_tail, im_tail = torch.chunk(tail, 2, dim=-1)\n",
    "\n",
    "    #Make phases of relations uniformly distributed in [-pi, pi]\n",
    "\n",
    "    phase_relation = relation/(embedding_range.item()/pi)\n",
    "\n",
    "    re_relation = torch.cos(phase_relation)\n",
    "    im_relation = torch.sin(phase_relation)\n",
    "\n",
    "    if mode == 'N1':\n",
    "        re_score = re_relation * re_tail + im_relation * im_tail\n",
    "        im_score = re_relation * im_tail - im_relation * re_tail\n",
    "        re_score = re_score - re_head\n",
    "        im_score = im_score - im_head\n",
    "    else:\n",
    "        re_score = re_head * re_relation - im_head * im_relation\n",
    "        im_score = re_head * im_relation + im_head * re_relation\n",
    "        re_score = re_score - re_tail\n",
    "        im_score = im_score - im_tail\n",
    "\n",
    "    score = torch.stack([re_score, im_score], dim = 0)\n",
    "    score = score.norm(dim = 0)\n",
    "\n",
    "    # score = gamma.item() - score.sum(dim = 2)\n",
    "    score = gamma.item() - score\n",
    "    return score.squeeze()\n",
    "\n",
    "def pRotatE(head, relation, tail, mode):\n",
    "    pi = 3.14159262358979323846\n",
    "    \n",
    "    #Make phases of entities and relations uniformly distributed in [-pi, pi]\n",
    "\n",
    "    phase_head = head/(embedding_range.item()/pi)\n",
    "    phase_relation = relation/(embedding_range.item()/pi)\n",
    "    phase_tail = tail/(embedding_range.item()/pi)\n",
    "\n",
    "    if mode == 'N1':\n",
    "        score = phase_head + (phase_relation - phase_tail)\n",
    "    else:\n",
    "        # print(phase_head.shape)\n",
    "        # print(phase_relation.shape)\n",
    "        # print(phase_tail.shape)\n",
    "        score = (phase_head + phase_relation) - phase_tail\n",
    "\n",
    "    score = torch.sin(score)            \n",
    "    score = torch.abs(score)\n",
    "\n",
    "    # score = gamma.item() - score.sum(dim = 2) * modulus\n",
    "    score = gamma.item() - score * modulus\n",
    "    return score.squeeze()\n",
    "\n",
    "\n",
    "model_func = {\n",
    "            'TransE': TransE,\n",
    "            # 'DistMult': DistMult,\n",
    "            # 'ComplEx': ComplEx,\n",
    "            'RotatE': RotatE,\n",
    "            'pRotatE': pRotatE\n",
    "        }\n",
    "\n",
    "def get_contribution(test_type=\"N1\"):\n",
    "    target_rel = 0\n",
    "    rst = torch.zeros(hidden_dim, num_rel)\n",
    "    print(rst.shape)\n",
    "    table_head, table_tail = get_table(all_true_triples)\n",
    "    skip_rel_idx = []\n",
    "    while target_rel < num_rel:\n",
    "        if test_type == 'rel_based':\n",
    "            if target_rel in _N1_rel:\n",
    "                test_type = \"N1\"\n",
    "            elif target_rel in _1N_rel:\n",
    "                test_type = \"1N\"\n",
    "            else:\n",
    "                test_type = \"N1\"\n",
    "\n",
    "        dataset = filtered_dataset(test_triples, [target_rel])\n",
    "        if len(dataset) <= 0:\n",
    "            print(\"rel \" + str(target_rel) + \" skip cause its size is zero\")\n",
    "            skip_rel_idx.append(target_rel)\n",
    "            target_rel += 1\n",
    "            continue\n",
    "        all_idx = []\n",
    "        all_std = []\n",
    "        all_rate = []\n",
    "        print(\"dataset size: \", len(dataset))\n",
    "        for head, rel, tail in dataset:\n",
    "            h = entity_embedding[head].unsqueeze(dim=0)\n",
    "            r = relation_embedding[rel].unsqueeze(dim=0)\n",
    "            t = entity_embedding[tail].unsqueeze(dim=0)\n",
    "\n",
    "            rate = model_func[name_model](h, r, t, test_type)\n",
    "            rate /= rate.sum()\n",
    "            all_rate.append(rate.detach())\n",
    "\n",
    "            if test_type == \"N1\":\n",
    "                all_score = model_func[name_model](entity_embedding, r, t, test_type)\n",
    "                std = torch.std(all_score, dim=0) # (D)\n",
    "                all_score[torch.tensor(table_head[(rel, tail)]).long()] -= 1000.0\n",
    "                all_score[head] += 1000.0\n",
    "                if name_dataset != \"FB15k-237\":\n",
    "                    all_score[tail] -= 1000.0\n",
    "                values, indices = torch.sort(all_score, dim=0, descending=True)\n",
    "                target_idx = (indices.T == head).nonzero()[:,1] + 1 # (D)\n",
    "            elif test_type == \"1N\":\n",
    "                all_score = model_func[name_model](h, r, entity_embedding, test_type)\n",
    "                std = torch.std(all_score, dim=0) # (D)\n",
    "                all_score[torch.tensor(table_tail[(rel, head)]).long()] -= 1000.0\n",
    "                if name_dataset != \"FB15k-237\":\n",
    "                    all_score[head] -= 1000.0\n",
    "                all_score[tail] += 1000.0\n",
    "                values, indices = torch.sort(all_score, dim=0, descending=True)\n",
    "                target_idx = (indices.T == tail).nonzero()[:,1] + 1 # (D)\n",
    "            all_std.append(std.detach())\n",
    "            all_idx.append(target_idx.detach()) # (D)\n",
    "\n",
    "        all_rate = torch.stack(all_rate, dim=0)\n",
    "        all_rate = (all_rate.float()).mean(dim=0)\n",
    "\n",
    "        all_std = torch.stack(all_std, dim=0)\n",
    "        all_std = (all_std.float()).mean(dim=0)\n",
    "        \n",
    "        all_idx = torch.stack(all_idx, dim=0)\n",
    "        all_idx = (all_idx.float()).mean(dim=0)\n",
    "        rst[:, target_rel] = all_std / (all_idx * all_rate)\n",
    "        # rst[:, target_rel] = all_std / (all_idx)\n",
    "        # rst[:, target_rel] = all_std\n",
    "        print(\"rel \" + str(target_rel) + \" done\")\n",
    "        target_rel += 1\n",
    "    \n",
    "    if len(skip_rel_idx) > 0:\n",
    "        rst[:, skip_rel_idx] = rst.mean(dim=-1).unsqueeze(dim=-1)\n",
    "    # log\n",
    "    # rst = torch.log10(rst)\n",
    "    # rst = rst - torch.min(rst, dim=0)\n",
    "    rst = rst - torch.min(rst, dim=0)[0]\n",
    "    # softmax\n",
    "    rst = rst.softmax(dim=0)\n",
    "    # to be weighted\n",
    "    one2one_dims = rst[:,complex_rel_idx_dict['one2one']] * proportion[complex_rel_idx_dict['one2one']].unsqueeze(dim=0) / torch.sum(proportion[complex_rel_idx_dict['one2one']])\n",
    "    one2one_dims = one2one_dims.sum(dim=-1).unsqueeze(dim=0)\n",
    "    many2one_dims = rst[:,complex_rel_idx_dict['many2one']] * proportion[complex_rel_idx_dict['many2one']].unsqueeze(dim=0) / torch.sum(proportion[complex_rel_idx_dict['many2one']])\n",
    "    many2one_dims = many2one_dims.sum(dim=-1).unsqueeze(dim=0)\n",
    "    one2many_dims = rst[:,complex_rel_idx_dict['one2many']] * proportion[complex_rel_idx_dict['one2many']].unsqueeze(dim=0) / torch.sum(proportion[complex_rel_idx_dict['one2many']])\n",
    "    one2many_dims = one2many_dims.sum(dim=-1).unsqueeze(dim=0)\n",
    "    many2many_dims = rst[:,complex_rel_idx_dict['many2many']] * proportion[complex_rel_idx_dict['many2many']].unsqueeze(dim=0) / torch.sum(proportion[complex_rel_idx_dict['many2many']])\n",
    "    many2many_dims = many2many_dims.sum(dim=-1).unsqueeze(dim=0)\n",
    "    # 取大于平均值为True\n",
    "    return torch.cat([one2one_dims, many2one_dims, one2many_dims, many2many_dims], dim=0)\n",
    "\n",
    "rst_head = get_contribution(\"N1\")\n",
    "rst_tail = get_contribution(\"1N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JSD, self).__init__()\n",
    "        self.kl = nn.KLDivLoss(reduction='batchmean', log_target=True)\n",
    "\n",
    "    def forward(self, p: torch.tensor, q: torch.tensor):\n",
    "        p, q = p.view(-1, p.size(-1)), q.view(-1, q.size(-1))\n",
    "        m = (0.5 * (p + q)).log()\n",
    "        return 0.5 * (self.kl(m, p.log()) + self.kl(m, q.log()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one2one\n",
      "torch.Size([196, 1]) torch.Size([199, 1])\n",
      "torch.Size([481, 1])\n",
      "\n",
      "many2one\n",
      "torch.Size([279, 1]) torch.Size([282, 1])\n",
      "torch.Size([493, 1])\n",
      "\n",
      "one2many\n",
      "torch.Size([245, 1]) torch.Size([248, 1])\n",
      "torch.Size([493, 1])\n",
      "\n",
      "many2many\n",
      "torch.Size([239, 1]) torch.Size([235, 1])\n",
      "torch.Size([496, 1])\n",
      "\n",
      "complex_rel_dist:  tensor([0.0134, 0.4745, 0.1516, 0.3606])\n",
      "contribute_dims:  tensor([0.2054, 0.2917, 0.2564, 0.2465])\n",
      "tensor(0.0738)\n"
     ]
    }
   ],
   "source": [
    "count_head = torch.zeros(num_complex_rel_type, hidden_dim) \n",
    "count_tail = torch.zeros(num_complex_rel_type, hidden_dim)\n",
    "for i in range(num_complex_rel_type):\n",
    "    count_head[i, :] = rst_head[i, :] > rst_head[i, :].mean()\n",
    "    count_tail[i, :] = rst_tail[i, :] > rst_tail[i, :].mean()\n",
    "names = ['one2one', 'many2one', 'one2many', 'many2many']\n",
    "for i in range(num_complex_rel_type):\n",
    "    print(names[i])\n",
    "    print(count_head[i, :].nonzero().shape, count_tail[i, :].nonzero().shape)\n",
    "    print((count_head[i, :] == count_tail[i, :]).nonzero().shape)\n",
    "    print()\n",
    "\n",
    "# complex_rel_dist\n",
    "# complex_rel_dist = torch.zeros(4)\n",
    "# complex_rel_dist[0] = proportion[complex_rel_idx_dict['one2one']].sum()\n",
    "# complex_rel_dist[1] = proportion[complex_rel_idx_dict['many2one']].sum()\n",
    "# complex_rel_dist[2] = proportion[complex_rel_idx_dict['one2many']].sum()\n",
    "# complex_rel_dist[3] = proportion[complex_rel_idx_dict['many2many']].sum()\n",
    "# complex_rel_dist /= complex_rel_dist.sum()\n",
    "print(\"complex_rel_dist: \", complex_rel_dist)\n",
    "\n",
    "# contribute_dims_dist\n",
    "contribute_dims = torch.zeros(4)\n",
    "contribute_dims[0] = (count_head[0, :].nonzero().shape[0] + count_tail[0, :].nonzero().shape[0]) / 2\n",
    "contribute_dims[1] = (count_head[1, :].nonzero().shape[0] + count_tail[1, :].nonzero().shape[0]) / 2\n",
    "contribute_dims[2] = (count_head[2, :].nonzero().shape[0] + count_tail[2, :].nonzero().shape[0]) / 2\n",
    "contribute_dims[3] = (count_head[3, :].nonzero().shape[0] + count_tail[3, :].nonzero().shape[0]) / 2\n",
    "contribute_dims /= contribute_dims.sum()\n",
    "print(\"contribute_dims: \", contribute_dims)\n",
    "\n",
    "# JS div\n",
    "jsd = JSD()\n",
    "output = jsd(complex_rel_dist, contribute_dims)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[197, 125, 105, 125],\n",
      "        [125, 280, 223, 228],\n",
      "        [105, 223, 246, 188],\n",
      "        [125, 228, 188, 237]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "### this is intersection matrix\n",
    "# matrix_head = torch.eye(4)\n",
    "# for i in range(4):\n",
    "#     for j in range(i+1, 4):\n",
    "#         matrix_head[i][j] = (count_head[i, :] * count_head[j, :]).nonzero().shape[0]\n",
    "\n",
    "# matrix_head = matrix_head + matrix_head.T\n",
    "\n",
    "# matrix_head[0,0] = (count_head[0, :].nonzero().shape[0] + count_tail[0, :].nonzero().shape[0]) / 2\n",
    "# matrix_head[1,1] = (count_head[1, :].nonzero().shape[0] + count_tail[1, :].nonzero().shape[0]) / 2\n",
    "# matrix_head[2,2] = (count_head[2, :].nonzero().shape[0] + count_tail[2, :].nonzero().shape[0]) / 2\n",
    "# matrix_head[3,3] = (count_head[3, :].nonzero().shape[0] + count_tail[3, :].nonzero().shape[0]) / 2\n",
    "\n",
    "# print(matrix_head.int())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15a52f39ef9f0df6a422ea601ee00a564afe4fc3158457e64ab6ffbff907cd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
